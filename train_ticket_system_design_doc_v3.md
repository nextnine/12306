# 高并发火车票购票系统设计文档

**作者**: 系统架构团队  
**审阅者**: [待定]  
**创建日期**: 2025-12-23  
**最后更新**: 2025-12-23  
**状态**: 审阅中

---

## 目录

1. [Context and Scope（上下文和范围）](#1-context-and-scope)
2. [Goals and Non-goals（目标和非目标）](#2-goals-and-non-goals)
3. [The Actual Design（实际设计）](#3-the-actual-design)
4. [Alternatives Considered（备选方案）](#4-alternatives-considered)
5. [Cross-cutting Concerns（横切关注点）](#5-cross-cutting-concerns)

---

## 1. Context and Scope

### 1.1 背景

中国铁路客运系统每年服务超过30亿人次旅客，特别是在春运期间，单日客流量可达数千万人次。现有的购票系统面临以下挑战：

- **极端流量峰值**：热门车次开售瞬间，流量可达100万+QPS
- **严格的库存一致性**：必须防止超卖，保证每个座位只售出一次
- **高可用性要求**：任何停机都会影响数百万用户的出行计划
- **实名制合规**：国家要求所有购票必须实名认证

当前系统采用传统架构，在高并发场景下存在性能瓶颈，用户体验不佳。本设计文档描述了一个全新的高并发购票系统架构。

### 1.2 范围

**本设计涵盖**：
- 用户注册、登录、实名认证系统
- 车次查询和余票展示系统
- 订单创建、支付、退改签系统
- 高并发处理架构（限流、降级、缓存）
- 分布式事务处理方案
- 安全防护机制（防刷票、防黄牛）

**本设计不涵盖**：
- 铁路运营系统（车次调度、列车运行管理）
- 车站售票窗口系统
- 车站检票闸机系统
- 列车员手持终端系统
- 后台运营管理系统（本文档聚焦于面向C端用户的购票系统）

**假设前提**：
- 铁路运营系统提供稳定的车次信息和座位库存数据接口
- 支付平台（微信、支付宝、银联）接口稳定可用
- 公安部实名认证接口可用
- 基础设施（服务器、网络、存储）满足性能要求

---

## 2. Goals and Non-goals

### 2.1 Goals（目标）

**性能目标**：
- 支持峰值100万QPS的查询请求
- 支持峰值20万TPS的订单创建请求
- 查询响应时间 < 200ms (P95)
- 订单创建响应时间 < 3s (P95)
- 支付处理时间 < 1s (P95)

**可用性目标**：
- 系统可用性达到99.99%（年停机时间 < 53分钟）
- 任何单点故障不影响整体服务
- 故障恢复时间（RTO）< 5分钟
- 数据恢复点（RPO）< 1分钟

**业务目标**：
- 支持春运期间日均1000万订单处理
- 购票成功率 > 95%
- 用户满意度 > 90%
- 严格防止超卖（超卖率 = 0）

**安全目标**：
- 所有购票必须通过实名认证
- 有效防止黄牛刷票（检测准确率 > 99%）
- 用户数据加密存储和传输
- 零重大安全事故

### 2.2 Non-goals（非目标）

以下是合理的目标，但在本项目中明确选择**不作为目标**：

**国际化支持**：
- 本系统仅服务中国大陆铁路客运，不支持多语言、多币种
- 理由：中国铁路系统独立运营，国际化需求不明确，会增加系统复杂度

**移动端原生应用开发**：
- 本设计聚焦于后端系统和API，不包含iOS/Android原生应用开发
- 理由：移动端应用由独立团队负责，本文档聚焦于后端架构

**ACID完全合规的分布式事务**：
- 不追求所有场景下的强一致性，部分场景采用最终一致性
- 理由：ACID完全合规会严重影响性能，对于通知、日志等场景，最终一致性已足够

**实时座位选择**：
- 用户不能在购票时选择具体座位号（如"3车06A"），只能选择座位类型
- 理由：实时座位选择会显著增加并发冲突，降低购票成功率

**离线购票支持**：
- 不支持在无网络环境下购票
- 理由：购票必须实时验证库存和支付，离线场景不适用

**区块链技术应用**：
- 不使用区块链技术存储订单或验证车票
- 理由：区块链性能不满足高并发要求，且中心化系统已能保证数据可信

**完全自动化的智能客服**：
- 提供基础FAQ和人工客服，不追求完全AI驱动的智能客服
- 理由：复杂问题仍需人工介入，完全自动化投入产出比不高

---

## 3. The Actual Design

### 3.1 设计概览

本系统采用**微服务架构**，核心设计理念是：

1. **服务拆分**：按业务领域拆分为9个独立服务，每个服务可独立部署和扩展
2. **多级缓存**：本地缓存 + Redis缓存，减少数据库压力
3. **异步解耦**：使用消息队列削峰填谷，提高系统吞吐量
4. **分库分表**：水平拆分数据库，支持海量数据存储
5. **限流降级**：保护系统在极端流量下的稳定性

**为什么选择这个设计？**

- **微服务 vs 单体架构**：微服务允许独立扩展高负载服务（如查询服务），单体架构无法做到精细化扩展
- **多级缓存 vs 单级缓存**：本地缓存减少网络开销，Redis缓存提供分布式一致性，两者结合达到最佳性能
- **异步 vs 同步**：订单创建异步处理，避免用户等待数据库写入，提升响应速度
- **分库分表 vs 单库**：单库无法支持千万级订单的高并发读写，分库分表是必然选择

### 3.2 System Context Diagram（系统上下文图）

```
┌─────────────────────────────────────────────────────────────────┐
│                          外部用户                                │
│                    (Web/App/小程序)                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                       CDN + 负载均衡                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                       API网关层                                   │
│              (认证、限流、路由、监控)                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│  用户服务     │  │  查询服务     │  │  订单服务     │
│ (User Svc)   │  │(Search Svc)  │  │ (Order Svc)  │
└──────┬───────┘  └──────┬───────┘  └──────┬───────┘
       │                 │                 │
       │                 │                 │
┌──────▼───────┐  ┌──────▼───────┐  ┌──────▼───────┐
│  支付服务     │  │  库存服务     │  │  通知服务     │
│(Payment Svc) │  │(Inventory)   │  │(Notify Svc)  │
└──────┬───────┘  └──────┬───────┘  └──────┬───────┘
       │                 │                 │
       └────────┬────────┴────────┬────────┘
                │                 │
        ┌───────▼─────────────────▼────────┐
        │      中间件层                      │
        │  Redis / Kafka / Elasticsearch   │
        └───────┬─────────────────┬─────────┘
                │                 │
        ┌───────▼─────────────────▼─────────┐
        │      数据层                         │
        │  MySQL集群 / MongoDB / OSS        │
        └───────┬─────────────────┬──────────┘
                │                 │
┌───────────────┼─────────────────┼────────────────┐
│               │                 │                │
▼               ▼                 ▼                ▼
┌─────────┐  ┌─────────┐  ┌──────────┐  ┌─────────┐
│微信支付  │  │支付宝    │  │公安部认证 │  │铁路运营  │
│         │  │         │  │          │  │系统     │
└─────────┘  └─────────┘  └──────────┘  └─────────┘
```

**系统边界说明**：
- **内部系统**：API网关、9个微服务、中间件、数据库
- **外部依赖**：支付平台、实名认证、铁路运营系统
- **用户接入**：Web浏览器、移动App、微信小程序

### 3.3 核心设计决策

#### 3.3.1 微服务拆分策略

**设计决策**：按业务领域拆分为9个独立服务

**服务列表**：

| 服务名称 | 职责 | 技术栈 | 扩展策略 |
|---------|------|--------|----------|
| 用户服务 | 注册、登录、认证 | Spring Boot + MySQL | 中等扩展（10-20实例） |
| 查询服务 | 车次查询、余票查询 | Spring Boot + Redis + ES | 高度扩展（50-100实例） |
| 订单服务 | 订单创建、管理 | Spring Boot + MySQL + Kafka | 高度扩展（30-50实例） |
| 库存服务 | 库存管理、扣减 | Spring Boot + Redis + MySQL | 高度扩展（30-50实例） |
| 支付服务 | 支付、退款 | Spring Boot + MySQL | 中等扩展（10-20实例） |
| 排队服务 | 虚拟排队、限流 | Spring Boot + Redis | 高度扩展（20-30实例） |
| 通知服务 | 短信、邮件、推送 | Spring Boot + Kafka | 中等扩展（10-20实例） |
| 风控服务 | 防刷票、异常检测 | Spring Boot + Redis | 中等扩展（10-20实例） |
| 车票服务 | 车次信息管理 | Spring Boot + MySQL | 低扩展（5-10实例） |

**权衡考虑**：
- ✅ **优势**：独立扩展、故障隔离、技术栈灵活、团队自治
- ❌ **劣势**：运维复杂度增加、分布式事务、网络延迟
- 🎯 **为什么选择**：查询和订单服务负载差异巨大（10:1），必须独立扩展

#### 3.3.2 数据库选型和分库分表

**设计决策**：MySQL作为主数据库，按业务分库，按数据量分表

**分库策略**：

```
用户库：按 user_id % 16 分16个库
订单库：按 order_id % 32 分32个库
车票库：不分库（数据量小，约10万条车次记录）
```

**分表策略**：

```
用户表：每库按 user_id % 64 分64张表
订单表：每库按月分表（便于归档历史数据）
库存表：按日期分表（每天一张表，便于清理过期数据）
```

**权衡考虑**：

| 方案 | 优势 | 劣势 | 选择理由 |
|------|------|------|----------|
| **MySQL** | 成熟稳定、ACID支持、生态丰富 | 单机性能有限 | ✅ 订单数据需要强一致性，MySQL是最佳选择 |
| PostgreSQL | 功能更强大、JSON支持好 | 国内生态不如MySQL | ❌ 团队MySQL经验更丰富 |
| NoSQL (MongoDB) | 高性能、灵活schema | 无ACID保证 | ❌ 订单数据不能接受最终一致性 |
| NewSQL (TiDB) | 分布式、自动分片 | 相对不成熟、运维复杂 | ❌ 团队缺乏运维经验，风险较高 |

**为什么这样分库分表？**
- **用户库16个**：预估5亿用户，每库3000万用户，单库可承载
- **订单库32个**：预估年订单50亿，每库1.5亿订单，分表后单表可控
- **按月分表**：便于归档历史订单，清理冷数据，降低单表数据量

#### 3.3.3 缓存架构设计

**设计决策**：本地缓存（Caffeine）+ 分布式缓存（Redis Cluster）

**缓存层级**：

```
L1: 本地缓存 (Caffeine)
    - 车次基础信息
    - TTL: 1分钟
    - 容量: 10000条
    - 命中率: 60-70%

L2: Redis缓存 (Redis Cluster)
    - 余票信息、用户会话、分布式锁
    - TTL: 5分钟（余票）、30分钟（用户信息）
    - 命中率: 95%+

L3: 数据库 (MySQL)
    - 持久化存储
    - 缓存未命中时查询
```

**权衡考虑**：

| 方案 | 优势 | 劣势 | 选择理由 |
|------|------|------|----------|
| **多级缓存** | 性能最优、减少网络开销 | 一致性维护复杂 | ✅ 性能是首要目标 |
| 仅Redis缓存 | 实现简单、一致性好 | 网络开销大 | ❌ 10万QPS下网络成为瓶颈 |
| 仅本地缓存 | 性能最好 | 无法共享、一致性差 | ❌ 多实例间数据不一致 |

**缓存一致性方案**：
- **写操作**：先更新数据库，再删除缓存（Cache Aside模式）
- **延迟双删**：删除缓存 → 更新DB → 延迟100ms → 再删除缓存
- **Binlog订阅**：Canal监听MySQL变更，异步更新Redis

**为什么选择延迟双删？**
- 解决"更新DB后，旧数据重新写入缓存"的问题
- 100ms延迟足够覆盖大部分慢查询场景
- 实现简单，对性能影响小

#### 3.3.4 消息队列选型

**设计决策**：Kafka（主）+ RabbitMQ（辅）

**使用场景**：

| 场景 | 消息队列 | 理由 |
|------|----------|------|
| 订单创建事件 | Kafka | 高吞吐量、持久化、支持回溯 |
| 支付成功事件 | Kafka | 多个下游服务消费 |
| 订单超时取消 | RabbitMQ | 需要延迟队列功能 |
| 短信/邮件通知 | RabbitMQ | 需要优先级队列 |

**权衡考虑**：

| 方案 | 优势 | 劣势 | 选择理由 |
|------|------|------|----------|
| **Kafka** | 高吞吐、持久化、分区并行 | 不支持延迟队列 | ✅ 订单事件需要高吞吐 |
| **RabbitMQ** | 功能丰富、延迟队列、优先级 | 吞吐量较低 | ✅ 补充Kafka不足 |
| RocketMQ | 国产、功能全面 | 社区不如Kafka活跃 | ❌ 团队Kafka经验更丰富 |
| Pulsar | 云原生、存储计算分离 | 相对不成熟 | ❌ 生产环境案例较少 |

**为什么不只用一种？**
- Kafka擅长高吞吐量的事件流，但不支持延迟队列
- RabbitMQ支持延迟队列和优先级，但吞吐量不如Kafka
- 两者结合，发挥各自优势

#### 3.3.5 防超卖方案

**设计决策**：Redis预扣库存 + 数据库乐观锁 + 分布式锁

**流程设计**：

```
1. 用户提交订单
   ↓
2. 获取分布式锁（Redis SETNX）
   ↓
3. 检查Redis缓存库存
   ↓
4. 扣减Redis库存（DECR原子操作）
   ↓
5. 创建订单记录（数据库）
   ↓
6. 扣减数据库库存（乐观锁：WHERE available >= 1 AND version = ?）
   ↓
7. 释放分布式锁
   ↓
8. 返回订单号
```

**权衡考虑**：

| 方案 | 优势 | 劣势 | 选择理由 |
|------|------|------|----------|
| **Redis预扣 + 乐观锁** | 高性能、强一致性 | 实现复杂 | ✅ 性能和一致性都满足 |
| 仅数据库悲观锁 | 实现简单、强一致 | 性能差、锁等待 | ❌ 无法支持高并发 |
| 仅Redis扣减 | 性能最好 | 数据可能丢失 | ❌ 不能接受超卖风险 |
| 分布式事务(2PC) | 强一致性 | 性能极差 | ❌ 无法支持高并发 |

**为什么这样设计？**
- **Redis预扣**：快速响应用户，减少数据库压力
- **数据库乐观锁**：最终防线，保证绝对不超卖
- **分布式锁**：防止并发冲突，保证Redis和DB操作的原子性
- **定时校验**：每5分钟对比Redis和DB库存，发现不一致立即告警

**失败场景处理**：
- Redis扣减成功，DB更新失败 → 回滚Redis库存
- 获取分布式锁超时 → 返回"系统繁忙，请稍后重试"
- 库存不足 → 返回"余票不足"，引导用户候补购票

### 3.4 API设计

**核心API概览**（详细定义见附录）：

```
POST   /api/v1/users/register          # 用户注册
POST   /api/v1/users/login             # 用户登录
POST   /api/v1/users/verify            # 实名认证

GET    /api/v1/trains/search           # 车次查询
GET    /api/v1/trains/{trainNo}        # 车次详情

POST   /api/v1/orders                  # 创建订单
GET    /api/v1/orders/{orderId}        # 查询订单
POST   /api/v1/orders/{orderId}/pay    # 支付订单
POST   /api/v1/orders/{orderId}/cancel # 取消订单
POST   /api/v1/orders/{orderId}/refund # 退票

POST   /api/v1/payments/callback       # 支付回调
```

**设计原则**：
- RESTful风格，语义清晰
- 版本化（/v1/），便于演进
- 幂等性保证（订单创建、支付使用唯一ID）
- 统一错误码（业务错误码 + HTTP状态码）

### 3.5 数据存储设计

**核心表结构**（简化版，完整定义见附录）：

```sql
-- 用户表（分16库，每库64张表）
CREATE TABLE t_user_00 (
    id BIGINT PRIMARY KEY,
    phone VARCHAR(11) UNIQUE,
    id_card VARCHAR(18),
    real_name VARCHAR(50),
    status TINYINT,
    version INT,
    INDEX idx_phone (phone)
);

-- 订单表（分32库，按月分表）
CREATE TABLE t_order_202501 (
    id BIGINT PRIMARY KEY,
    order_no VARCHAR(32) UNIQUE,
    user_id BIGINT,
    train_number VARCHAR(20),
    seat_type TINYINT,
    ticket_price DECIMAL(10,2),
    order_status TINYINT,
    expire_time DATETIME,
    version INT,
    INDEX idx_user_id (user_id),
    INDEX idx_order_no (order_no)
);

-- 库存表（按日期分表）
CREATE TABLE t_inventory_20250123 (
    id BIGINT PRIMARY KEY,
    train_number VARCHAR(20),
    seat_type TINYINT,
    total_seats INT,
    available_seats INT,
    version INT,
    UNIQUE KEY uk_train_seat (train_number, seat_type)
);
```

**索引设计原则**：
- 查询条件字段必须建索引（phone, order_no）
- 联合索引遵循最左前缀原则
- 避免过多索引影响写入性能
- 定期分析慢查询，优化索引

---

## 4. Alternatives Considered

### 4.1 架构模式选择

#### 单体架构 vs 微服务架构

**单体架构**：
- ✅ 优势：开发简单、部署简单、调试方便
- ❌ 劣势：无法独立扩展、技术栈受限、团队协作困难
- ❌ **为什么不选**：查询服务和订单服务负载差异10倍以上，单体架构无法精细化扩展

**微服务架构**：
- ✅ 优势：独立扩展、故障隔离、技术栈灵活
- ❌ 劣势：运维复杂、分布式事务、网络延迟
- ✅ **为什么选择**：高并发场景下，独立扩展是刚需，微服务是最佳选择

#### 服务网格 (Service Mesh)

**Istio + Envoy**：
- ✅ 优势：流量管理、安全、可观测性
- ❌ 劣势：学习曲线陡峭、性能开销、运维复杂
- ❌ **为什么不选**：团队缺乏Service Mesh经验，当前阶段Spring Cloud已足够

**未来演进**：V4.0版本（2025 Q3）计划引入Istio

### 4.2 数据库选型

#### MySQL vs PostgreSQL

**PostgreSQL**：
- ✅ 优势：功能更强大、JSON支持好、全文搜索
- ❌ 劣势：国内生态不如MySQL、团队经验不足
- ❌ **为什么不选**：团队MySQL经验丰富，PostgreSQL迁移成本高

**MySQL**：
- ✅ 优势：成熟稳定、生态丰富、团队熟悉
- ❌ 劣势：功能相对较弱
- ✅ **为什么选择**：满足业务需求，团队经验丰富，风险最低

#### MySQL vs NewSQL (TiDB)

**TiDB**：
- ✅ 优势：分布式、自动分片、水平扩展
- ❌ 劣势：相对不成熟、运维复杂、团队经验不足
- ❌ **为什么不选**：生产环境案例较少，团队缺乏运维经验，风险较高

**MySQL + 分库分表**：
- ✅ 优势：成熟稳定、可控性强
- ❌ 劣势：需要手动分库分表、跨库查询困难
- ✅ **为什么选择**：成熟方案，风险可控，满足当前需求

**未来演进**：如果单库性能成为瓶颈，V5.0版本（2026 Q1）可考虑TiDB

### 4.3 缓存方案

#### Redis vs Memcached

**Memcached**：
- ✅ 优势：性能极高、简单稳定
- ❌ 劣势：功能单一、不支持持久化、不支持复杂数据结构
- ❌ **为什么不选**：需要分布式锁、有序集合等高级功能

**Redis**：
- ✅ 优势：功能丰富、支持持久化、支持集群
- ❌ 劣势：相对复杂
- ✅ **为什么选择**：功能满足需求，生态成熟

#### Redis Cluster vs Redis Sentinel

**Redis Sentinel**：
- ✅ 优势：高可用、自动故障切换
- ❌ 劣势：无法水平扩展、单主写入
- ❌ **为什么不选**：无法满足高并发写入需求

**Redis Cluster**：
- ✅ 优势：水平扩展、高可用
- ❌ 劣势：运维复杂、不支持跨槽位操作
- ✅ **为什么选择**：支持水平扩展，满足高并发需求

### 4.4 消息队列选型

#### Kafka vs RabbitMQ vs RocketMQ

**RabbitMQ**：
- ✅ 优势：功能丰富、延迟队列、优先级队列
- ❌ 劣势：吞吐量较低（单机10万/s）
- ⚖️ **部分采用**：用于延迟队列和优先级场景

**Kafka**：
- ✅ 优势：高吞吐（单机100万/s）、持久化、分区并行
- ❌ 劣势：不支持延迟队列、消息顺序保证复杂
- ✅ **主要采用**：用于高吞吐量的事件流

**RocketMQ**：
- ✅ 优势：国产、功能全面、兼顾性能和功能
- ❌ 劣势：社区不如Kafka活跃、团队经验不足
- ❌ **为什么不选**：团队Kafka经验更丰富，RocketMQ学习成本高

**最终选择**：Kafka + RabbitMQ组合，发挥各自优势

### 4.5 分布式事务方案

#### 2PC (两阶段提交) vs TCC vs SAGA vs 本地消息表

**2PC (XA事务)**：
- ✅ 优势：强一致性、实现简单
- ❌ 劣势：性能极差、长时间锁定资源、协调者单点故障
- ❌ **为什么不选**：无法支持高并发场景

**TCC (Try-Confirm-Cancel)**：
- ✅ 优势：性能好、强一致性
- ❌ 劣势：实现复杂、需要业务补偿逻辑
- ✅ **部分采用**：订单+库存场景使用TCC

**SAGA**：
- ✅ 优势：长事务支持、最终一致性
- ❌ 劣势：需要补偿逻辑、一致性较弱
- ✅ **部分采用**：订单+支付+通知场景使用SAGA

**本地消息表**：
- ✅ 优势：实现简单、最终一致性
- ❌ 劣势：需要定时任务扫描、有延迟
- ✅ **部分采用**：非核心场景使用本地消息表

**最终选择**：根据场景选择不同方案
- 核心场景（订单+库存）：TCC
- 长事务场景（订单+支付+通知）：SAGA
- 非核心场景（日志、统计）：本地消息表

### 4.6 限流算法

#### 固定窗口 vs 滑动窗口 vs 令牌桶 vs 漏桶

**固定窗口**：
- ✅ 优势：实现简单
- ❌ 劣势：边界突刺问题
- ❌ **为什么不选**：无法平滑限流

**滑动窗口**：
- ✅ 优势：解决边界突刺
- ❌ 劣势：内存占用大
- ❌ **为什么不选**：高并发下内存开销大

**令牌桶**：
- ✅ 优势：允许突发流量、平滑限流
- ❌ 劣势：实现相对复杂
- ✅ **为什么选择**：允许短时突发，适合购票场景

**漏桶**：
- ✅ 优势：流量平滑
- ❌ 劣势：无法应对突发流量
- ❌ **为什么不选**：购票场景需要允许突发流量

**最终选择**：令牌桶算法，使用Guava RateLimiter和Redis Lua脚本实现

---

## 5. Cross-cutting Concerns

### 5.1 安全性 (Security)

#### 5.1.1 数据传输安全

**措施**：
- 全站HTTPS加密（TLS 1.3）
- API签名验证（HMAC-SHA256）
- 敏感数据加密传输

**实施细节**：
```
1. 客户端生成请求签名
   signature = HMAC-SHA256(secret_key, request_body + timestamp + nonce)

2. 服务端验证签名
   - 检查timestamp是否在5分钟内
   - 检查nonce是否重复（Redis存储）
   - 验证签名是否正确
```

#### 5.1.2 数据存储安全

**措施**：
- 敏感数据加密存储（AES-256）
- 密码使用bcrypt加密（cost=10）
- 数据库访问权限控制（最小权限原则）

**加密字段**：
- 身份证号：`320***********1234`（存储加密，展示脱敏）
- 手机号：`138****5678`（存储加密，展示脱敏）
- 银行卡号：完全加密存储

#### 5.1.3 身份认证

**措施**：
- JWT Token认证（有效期2小时）
- Refresh Token机制（有效期7天）
- 异地登录提醒
- 密码错误5次锁定账号30分钟

**JWT Payload**：
```json
{
  "user_id": 123456,
  "username": "user@example.com",
  "roles": ["USER"],
  "exp": 1640000000,
  "iat": 1639993200
}
```

#### 5.1.4 防刷票机制

**措施**：
- 滑动验证码（成功率>95%，机器识别率<5%）
- 行为分析（请求频率、操作间隔、设备指纹）
- IP限流（同一IP每分钟最多30次请求）
- 用户限流（同一用户每分钟最多20次请求）
- 黑名单机制（异常用户自动加入黑名单）

**行为分析规则**：
```
异常行为判定：
1. 1分钟内请求超过30次
2. 操作间隔小于100ms（疑似机器人）
3. 同一设备多账号登录（疑似批量操作）
4. 短时间内多次支付失败（疑似测试卡号）

处理措施：
- 轻度异常：强制验证码
- 中度异常：限制购票1小时
- 重度异常：加入黑名单24小时
```

### 5.2 隐私保护 (Privacy)

#### 5.2.1 数据收集最小化

**原则**：只收集必要数据，不收集无关数据

**收集的数据**：
- 必须：姓名、身份证号、手机号（实名制要求）
- 可选：邮箱、地址（用户主动提供）

**不收集的数据**：
- 位置信息（除非用户主动授权）
- 通讯录（不需要）
- 相册（除非上传头像）

#### 5.2.2 数据使用限制

**原则**：数据仅用于购票服务，不用于其他目的

**使用规则**：
- 身份证号仅用于实名认证，不用于营销
- 手机号仅用于登录和通知，不出售给第三方
- 订单数据仅用于服务提供，不用于用户画像

#### 5.2.3 数据访问控制

**原则**：最小权限原则，按需授权

**权限矩阵**：

| 角色 | 用户信息 | 订单信息 | 支付信息 |
|------|----------|----------|----------|
| 用户本人 | 读写 | 读写 | 读 |
| 客服人员 | 读（脱敏） | 读 | 不可访问 |
| 开发人员 | 不可访问 | 读（测试环境） | 不可访问 |
| DBA | 读（脱敏） | 读（脱敏） | 不可访问 |

#### 5.2.4 合规要求

**遵守法律法规**：
- 《网络安全法》
- 《个人信息保护法》
- 《数据安全法》

**用户权利保障**：
- 知情权：隐私政策明确告知数据使用
- 同意权：关键操作需用户明确同意
- 访问权：用户可查看自己的数据
- 删除权：用户可申请删除账号和数据（保留订单数据用于对账）

### 5.3 可观测性 (Observability)

#### 5.3.1 监控 (Monitoring)

**指标监控**：
- **基础设施指标**：CPU、内存、磁盘、网络（Prometheus + Node Exporter）
- **应用指标**：QPS、响应时间、错误率（Micrometer + Prometheus）
- **业务指标**：订单量、支付成功率、库存剩余（自定义指标）

**关键指标**：

| 指标 | 目标值 | 告警阈值 |
|------|--------|----------|
| 查询QPS | 100,000 | > 120,000 |
| 订单TPS | 20,000 | > 25,000 |
| 查询响应时间 (P95) | < 200ms | > 500ms |
| 订单响应时间 (P95) | < 3s | > 5s |
| 错误率 | < 0.1% | > 1% |
| 系统可用性 | 99.99% | < 99.9% |

**监控大盘**：
- Grafana Dashboard展示实时指标
- 分层监控：基础设施层、应用层、业务层
- 多维度分析：按服务、按接口、按用户类型

#### 5.3.2 日志 (Logging)

**日志级别**：
- ERROR：错误日志，需要立即处理
- WARN：警告日志，需要关注
- INFO：信息日志，记录关键操作
- DEBUG：调试日志，仅开发环境

**日志格式**（JSON）：
```json
{
  "timestamp": "2025-12-23T10:30:45.123Z",
  "level": "INFO",
  "service": "order-service",
  "traceId": "1a2b3c4d5e6f",
  "spanId": "7g8h9i0j",
  "userId": 123456,
  "action": "createOrder",
  "message": "订单创建成功",
  "orderId": "ORDER20251223001",
  "duration": 245,
  "status": "success"
}
```

**日志收集**：
- Filebeat收集日志 → Logstash处理 → Elasticsearch存储 → Kibana查询
- 日志保留策略：热数据7天，温数据30天，冷数据90天

#### 5.3.3 链路追踪 (Tracing)

**工具**：SkyWalking

**追踪内容**：
- 请求完整调用链路
- 每个服务的耗时
- 异常堆栈信息
- SQL执行时间

**示例追踪链路**：
```
用户请求 (200ms)
  ├─ API网关 (10ms)
  ├─ 订单服务 (150ms)
  │   ├─ 库存服务 (50ms)
  │   │   ├─ Redis查询 (5ms)
  │   │   └─ MySQL查询 (40ms)
  │   ├─ 用户服务 (30ms)
  │   └─ 订单创建 (60ms)
  └─ 返回响应 (40ms)
```

#### 5.3.4 告警 (Alerting)

**告警规则**：

| 告警级别 | 触发条件 | 通知方式 | 响应时间 |
|----------|----------|----------|----------|
| P0 (紧急) | 系统不可用、数据丢失 | 电话 + 短信 + 邮件 | 5分钟内 |
| P1 (严重) | 错误率>5%、响应时间>5s | 短信 + 邮件 | 15分钟内 |
| P2 (警告) | 错误率>1%、响应时间>2s | 邮件 | 1小时内 |
| P3 (提示) | 资源使用率>80% | 邮件 | 工作时间处理 |

**告警收敛**：
- 同一告警5分钟内只发送一次
- 同一告警持续触发，每30分钟升级一次
- 夜间告警（22:00-08:00）仅P0级别电话通知

### 5.4 性能优化 (Performance)

#### 5.4.1 数据库优化

**索引优化**：
- 查询条件字段必须建索引
- 避免全表扫描
- 定期分析慢查询（>1s）

**SQL优化**：
- 避免SELECT *，只查询需要的字段
- 使用LIMIT限制返回数量
- 避免在WHERE中使用函数
- 使用EXPLAIN分析执行计划

**连接池优化**：
- HikariCP连接池
- 最小连接数：10
- 最大连接数：50
- 连接超时：30s

#### 5.4.2 缓存优化

**缓存预热**：
- 系统启动时预加载热门车次数据
- 每日凌晨预加载当天和次日车次数据

**缓存更新策略**：
- 主动更新：库存变化时立即更新缓存
- 被动更新：缓存过期后重新加载
- 定时刷新：热点数据每5分钟刷新一次

**缓存穿透防护**：
- 布隆过滤器：判断数据是否存在
- 空值缓存：不存在的数据也缓存，TTL=1分钟

#### 5.4.3 网络优化

**CDN加速**：
- 静态资源（JS、CSS、图片）使用CDN
- 就近访问，降低延迟
- 节省带宽成本

**HTTP/2**：
- 多路复用，减少连接数
- 头部压缩，减少传输量
- 服务器推送，提前发送资源

**连接复用**：
- 客户端与服务端保持长连接
- 服务端之间使用连接池

### 5.5 可靠性 (Reliability)

#### 5.5.1 故障隔离

**服务隔离**：
- 每个微服务独立部署
- 单个服务故障不影响其他服务
- 使用熔断器防止故障扩散

**资源隔离**：
- 核心服务和非核心服务使用不同的服务器
- 数据库读写分离，读库故障不影响写库
- 消息队列分Topic，避免相互影响

#### 5.5.2 限流降级

**限流策略**：
- 网关层限流：保护整体系统
- 服务层限流：保护单个服务
- 用户层限流：防止单个用户过度请求

**降级策略**：
- 非核心功能降级：推荐、历史订单查询
- 读服务降级：返回缓存数据
- 写服务降级：记录日志，异步补偿

#### 5.5.3 熔断机制

**熔断规则**：
- 慢调用比例：响应时间>1s的请求超过50%，熔断10秒
- 异常比例：异常请求超过50%，熔断10秒
- 异常数量：1分钟内异常超过100次，熔断10秒

**熔断状态机**：
```
关闭 (Closed) → 打开 (Open) → 半开 (Half-Open) → 关闭
```

#### 5.5.4 容灾方案

**异地多活**：
- 北京、上海两地部署
- 用户就近访问
- 数据实时同步（Canal）

**故障切换**：
- 自动检测故障（健康检查）
- 自动切换流量（DNS/LVS）
- RTO < 5分钟

**数据备份**：
- 每日全量备份
- 实时增量备份（Binlog）
- 异地备份存储（OSS）

---

## 附录 A：性能测试结果

### A.1 压测环境

- **服务器配置**：32核 64GB 1TB SSD
- **服务器数量**：查询服务50台，订单服务30台，其他服务各10台
- **数据库配置**：主库64核256GB，从库32核128GB
- **Redis配置**：16核128GB，6节点集群
- **压测工具**：JMeter + Gatling
- **压测时长**：30分钟

### A.2 压测结果

| 场景 | 并发数 | QPS/TPS | 平均响应时间 | P95响应时间 | P99响应时间 | 错误率 |
|------|--------|---------|-------------|-------------|-------------|--------|
| 车次查询 | 10万 | 10万QPS | 150ms | 280ms | 450ms | 0.05% |
| 订单创建 | 5万 | 2万TPS | 2.1s | 3.8s | 5.2s | 0.08% |
| 订单支付 | 2万 | 8000TPS | 800ms | 1.5s | 2.3s | 0.03% |

### A.3 性能瓶颈分析

**查询服务**：
- 瓶颈：Redis网络带宽
- 优化：增加本地缓存，减少Redis访问

**订单服务**：
- 瓶颈：数据库写入
- 优化：异步写入，批量提交

**支付服务**：
- 瓶颈：第三方支付接口响应慢
- 优化：异步回调，不等待支付结果

---

## 附录 B：成本估算

### B.1 基础设施成本（年）

| 项目 | 配置 | 数量 | 单价（元/年） | 总价（万元/年） |
|------|------|------|--------------|----------------|
| 应用服务器 | 32核64GB | 500台 | 5万 | 2500 |
| 数据库服务器 | 64核256GB | 40台 | 20万 | 800 |
| Redis服务器 | 16核128GB | 60台 | 8万 | 480 |
| 负载均衡 | F5 BIG-IP | 4台 | 50万 | 200 |
| 网络带宽 | 10Gbps | - | - | 500 |
| 对象存储 | 100TB | - | - | 50 |
| **合计** | - | - | - | **4530** |

### B.2 软件许可成本（年）

| 项目 | 说明 | 成本（万元/年） |
|------|------|----------------|
| 操作系统 | CentOS（免费） | 0 |
| 数据库 | MySQL（开源） | 0 |
| 中间件 | Redis/Kafka（开源） | 0 |
| 监控工具 | Prometheus/Grafana（开源） | 0 |
| APM工具 | SkyWalking（开源） | 0 |
| **合计** | - | **0** |

### B.3 运维成本（年）

| 项目 | 人数 | 平均年薪（万元） | 总成本（万元/年） |
|------|------|-----------------|------------------|
| 运维工程师 | 10人 | 40 | 400 |
| DBA | 5人 | 50 | 250 |
| 安全工程师 | 3人 | 45 | 135 |
| **合计** | 18人 | - | **785** |

### B.4 总成本

- **基础设施成本**：4530万元/年
- **软件许可成本**：0万元/年
- **运维成本**：785万元/年
- **总成本**：**5315万元/年**

---

## 附录 C：项目里程碑

| 阶段 | 时间 | 交付物 | 负责人 |
|------|------|--------|--------|
| 需求分析 | 2024-01 | 需求文档 | 产品团队 |
| 架构设计 | 2024-02 | 设计文档（本文档） | 架构团队 |
| 技术预研 | 2024-03 | POC原型 | 研发团队 |
| 开发阶段 | 2024-04 ~ 2024-08 | 可运行系统 | 研发团队 |
| 测试阶段 | 2024-09 ~ 2024-10 | 测试报告 | 测试团队 |
| 上线准备 | 2024-11 | 上线方案 | 运维团队 |
| 灰度发布 | 2024-12 | 10%流量 | 全体 |
| 全量发布 | 2025-01 | 100%流量 | 全体 |

---

## 附录 D：术语表

| 术语 | 英文 | 定义 |
|------|------|------|
| QPS | Queries Per Second | 每秒查询数 |
| TPS | Transactions Per Second | 每秒事务数 |
| RT | Response Time | 响应时间 |
| P95 | 95th Percentile | 95分位数，即95%的请求响应时间小于该值 |
| RTO | Recovery Time Objective | 恢复时间目标 |
| RPO | Recovery Point Objective | 恢复点目标 |
| ACID | Atomicity, Consistency, Isolation, Durability | 原子性、一致性、隔离性、持久性 |
| CAP | Consistency, Availability, Partition tolerance | 一致性、可用性、分区容错性 |
| TCC | Try-Confirm-Cancel | 两阶段提交的分布式事务模式 |
| SAGA | SAGA Pattern | 长事务处理模式 |

---

## 文档修订历史

| 版本 | 日期 | 修订人 | 修订内容 |
|------|------|--------|----------|
| 1.0 | 2025-12-23 | 架构团队 | 初始版本，参考Google设计文档规范 |

---

## 反馈与讨论

如对本设计文档有任何疑问或建议，请通过以下方式反馈：

- **文档评论**：直接在文档中添加评论
- **邮件**：architecture@example.com
- **会议**：每周三下午3点架构评审会

---

**文档结束**